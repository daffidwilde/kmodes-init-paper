{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Generating a population of datasets using a genetic algorithm\n", "---\n", "\n", "## Motivation\n", "---\n", "Preliminary tests on relatively small datasets has shown that deliberately choosing a fairer starting point for the algorithm (i.e. by assigning potential centroids to points in the data by solving a matching game) does not necessarily improve the performance of the overall $k$-modes algorithm.\n", "\n", "The hope is to develop a set of datasets which are better clustered by our matching initialisation than by Cao's method (the leading competitor). We will develop this set as a population in a genetic algorithm.\n", "\n", "## Method\n", "---\n", "#### 1. Beginning with an initial set of randomly-generated categorical datasets\n", " - Defined by their number of **rows, columns, and clusters** we will cluster them each by our method and Cao's.\n", "\n", "#### 2. Select two parents that are well-performing\n", " - Performance is given by our **objective function**\n", " - We stipulate some level of **difference** between these parent datasets to **maintain** some population **diversity**. By doing this, we avoid falling into a local minimum too soon.\n", "\n", "#### 3. Create an offspring based on some crossover operation\n", " - This will likely be some mix of blending the columns of our parent datasets, and resizing it to be full.\n", "\n", "#### 4. Select some underperforming dataset and replace it with the offspring. Go to 2 until some stopping criterion is met\n", "\n", "\n", "At each generation, we 'roll a dice' and mutate a dataset at random according to some pre-defined mutation rate. By mutating a member of our population, we force some diversity even when we are converging to some 'stable' population of datasets. This mutation operation will be similar to the crossover operation."]}, {"cell_type": "code", "execution_count": 102, "metadata": {}, "outputs": [], "source": ["from kmodes.kmodes import KModes\n", "from sklearn.datasets import make_blobs\n", "\n", "import operator\n", "import itertools\n", "\n", "import pandas as pd\n", "import numpy as np\n"]}, {"cell_type": "code", "execution_count": 73, "metadata": {}, "outputs": [], "source": ["def pointwise_dissim(x, y):\n", "    return np.sum(x != y, axis=0)\n", "\n", "\n", "def dissim(Y, x):\n", "    return np.sum(Y != x, axis=1)\n"]}, {"cell_type": "code", "execution_count": 74, "metadata": {}, "outputs": [], "source": ["class DataSet(object):\n", "    \"\"\" A dataset object, defined by its number of rows, columns and clusters, and a generator seed. \"\"\"\n", "\n", "    def __init__(self, n_rows, n_cols, n_clusters, seed):\n", "\n", "        self.n_rows = n_rows\n", "        self.n_cols = n_cols\n", "        self.n_clusters = n_clusters\n", "        self.seed = seed\n", "\n", "        np.random.seed(self.seed)\n", "        self.cluster_std = (0.5 - 0.01) * np.random.random() + 0.01\n", "\n", "    def get_params(self):\n", "        \"\"\" Return the parameters of our dataset as a tuple for easy access. \"\"\"\n", "        return self.n_rows, self.n_cols, self.n_clusters, self.seed\n", "\n", "    def get_dataframe(self):\n", "        \"\"\" Generate the dataset itself as a pandas.DataFrame object. \"\"\"\n", "\n", "        data, target = make_blobs(\n", "            self.n_rows,\n", "            self.n_cols,\n", "            self.n_clusters,\n", "            self.cluster_std,\n", "            center_box=(0, 1),\n", "            random_state=self.seed,\n", "        )\n", "\n", "        data = np.round(data, 0)\n", "        dataframe = pd.DataFrame(\n", "            {f\"attr{col}\": data[:, col] for col in range(data.shape[1])}\n", "        )\n", "\n", "        return dataframe\n", "\n", "    def get_clustering(self, init):\n", "        \"\"\" Cluster the dataset into `n_clusters` parts, initialised by method `init`. \"\"\"\n", "\n", "        km = KModes(n_clusters=self.n_clusters, init=init, n_init=10)\n", "        km.fit_predict(self.get_dataframe())\n", "\n", "        return km\n", "\n", "    def fitness(self):\n", "        \"\"\" Find the fitness of a dataset by clustering it by Cao's method, and our own;\n", "        return the difference between their costs. \"\"\"\n", "\n", "        cao = self.get_clustering(\"cao\")\n", "        matching_best = self.get_clustering(\"matching_best\")\n", "\n", "        return matching_best.cost_ - cao.cost_\n"]}, {"cell_type": "code", "execution_count": 59, "metadata": {}, "outputs": [], "source": ["def generate_first_population(population_size):\n", "    \"\"\" Given some population size (this also acts as a max seed),\n", "    create an initial set of DataSet objects. \"\"\"\n", "\n", "    population = []\n", "    seed = 0\n", "\n", "    while seed < population_size:\n", "\n", "        np.random.seed(seed)\n", "        n_rows = np.random.randint(100, 10000)\n", "        n_cols = np.random.randint(4, 500)\n", "        n_clusters = np.random.randint(3, 20)\n", "\n", "        dataset = DataSet(n_rows, n_cols, n_clusters, seed)\n", "        population.append(dataset)\n", "        seed += 1\n", "\n", "    return population\n"]}, {"cell_type": "code", "execution_count": 60, "metadata": {}, "outputs": [], "source": ["def get_ordered_population(population):\n", "    \"\"\" Order the current population by their fitness in descending order. \"\"\"\n", "\n", "    ordered_population = {}\n", "    for individual in population:\n", "        ordered_population[individual] = individual.fitness()\n", "\n", "    return sorted(ordered_population.items(), key=operator.itemgetter(1), reverse=True)\n"]}, {"cell_type": "code", "execution_count": 106, "metadata": {}, "outputs": [], "source": ["def select_breeders(ordered_population, best_sample, lucky_sample):\n", "    \"\"\" Given a population, select breeders for the next generation.\n", "    \n", "    Parameters\n", "    ----------\n", "    ordered_population : dict\n", "        A sorted dictionary where keys are current individuals, each\n", "        with their fitness as the corresponding value.\n", "    best_sample : int\n", "        The number of best performing individuals to take to breed for\n", "        the next generation.\n", "    lucky_sample : int\n", "        The number of individuals to be randomly selected to breed for\n", "        the next generation.\n", "\n", "    Returns\n", "    -------\n", "    breeders : list\n", "        The individuals to breed for the next generation.\n", "    \"\"\"\n", "\n", "    np.random.seed(0)\n", "    breeders = []\n", "    ranked_individuals = list(ordered_population.items())\n", "    for i in range(best_sample):\n", "        individual = ranked_individuals.pop(0)[0]\n", "        breeders.append(individual)\n", "\n", "    for j in range(lucky_sample):\n", "        individual = np.random.choice(ranked_individuals)[0]\n", "        breeders.append(individual)\n", "\n", "    np.random.shuffle(breeders)\n", "    return breeders\n"]}, {"cell_type": "code", "execution_count": 107, "metadata": {}, "outputs": [], "source": ["def create_child(parent1, parent2):\n", "    \"\"\" Given two parents, randomly select one of the parameters of either\n", "    parent or their average. Then return a new DataSet instance as 'their\n", "    child' with these selected parameters. \"\"\"\n", "\n", "    params = np.empty((3, 4))\n", "    for row, parent in enumerate([parent1, parent2]):\n", "        params[row, :] = parent.get_params()\n", "        params[2, :] += parent.get_params()\n", "    params[2, :] //= 2\n", "\n", "    child_params = (np.random.choice(params[:, col]) for col in range(4))\n", "    child = DataSet(*child_params)\n", "\n", "    return child\n"]}, {"cell_type": "code", "execution_count": 108, "metadata": {}, "outputs": [], "source": ["def create_children(breeders, population_size, max_children):\n", "    \"\"\" All breeders reproduce with one another, where each pair of parents\n", "    produce a number of children decided by the modulo product of their seeds.\n", "    A maximum number of children is passed as a parameter here. \"\"\"\n", "\n", "    next_population = []\n", "    for parent1, parent2 in itertools.combinations(breeders, r=2):\n", "        number_children = parent1.seed * parent2.seed % max_children\n", "        np.random.seed(number_children)\n", "        for child in range(number_children):\n", "            if len(next_population) < population_size:\n", "                next_population.append(create_child(parent1, parent2))\n", "\n", "    return next_population\n"]}, {"cell_type": "code", "execution_count": 117, "metadata": {}, "outputs": [], "source": ["def mutation(individual, population_size):\n", "    \"\"\" Mutate an individual by changing its seed, i.e. the same structural\n", "    parameters but with new values. \"\"\"\n", "\n", "    individual.seed = np.random.randint(population_size)\n", "    return individual\n"]}, {"cell_type": "code", "execution_count": 141, "metadata": {}, "outputs": [], "source": ["def mutate_population(population, mutation_rate):\n", "    \"\"\" Mutate individuals in the population at each generation according to\n", "    a mutation_rate, i.e. the proportion of the population to be mutated. \"\"\"\n", "\n", "    for i, individual in enumerate(population):\n", "        if np.random.random() < mutation_rate:\n", "            individual = mutation(individual)\n", "\n", "    return population\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["%%timeit\n", "\n", "population_size = 10\n", "max_children = population_size // 4\n", "population = generate_first_population(population_size)\n", "step = 0\n", "while step < 5:\n", "    ordered_population = get_ordered_population(population)\n", "    breeders = select_breeders(ordered_population)\n", "    new_generation = create_children(breeders, population_size, max_children)\n", "    population = mutate_population(new_generation)"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["0\n"]}], "source": ["for _ in range(1):\n", "    print(_)\n"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/plain": ["[2, 3, 4, 5]"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["a = [1, 2, 3, 4, 5]\n", "\n", "del a[a.index(1)]\n", "\n", "a\n"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": ["from genetic_data.pdfs import Gamma, Poisson\n"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["g = Gamma(100)\n"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"data": {"text/plain": ["<genetic_data.pdfs.Gamma at 0x11290f5c0>"]}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": ["Gamma."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.5"}}, "nbformat": 4, "nbformat_minor": 2}